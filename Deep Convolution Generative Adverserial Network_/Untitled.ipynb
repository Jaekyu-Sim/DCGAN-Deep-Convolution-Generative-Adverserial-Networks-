{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JAEKYU\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-37965886b198>:3: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\JAEKYU\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\JAEKYU\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\JAEKYU\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\JAEKYU\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\JAEKYU\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_noise_vector(batch_size, noise_size):\n",
    "    noise_vector = np.random.normal(size=(batch_size, noise_size))\n",
    "    return noise_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model\n"
     ]
    }
   ],
   "source": [
    "class DCGAN(object):\n",
    "    def __init__(self, sess, batch_size):\n",
    "        self.sess = sess\n",
    "        self.batch_size = batch_size\n",
    "        self.input_channel = 1\n",
    "        self.noise_size = 100\n",
    "        self.input_width = 28\n",
    "        self.input_height = 28\n",
    "        self.parameter()\n",
    "        self.model()\n",
    "        #self.generator()\n",
    "        #self.discriminator()\n",
    "        \n",
    "    def parameter(self):\n",
    "        #input parameter\n",
    "        self.X = tf.placeholder(dtype=tf.float32, shape=[None, self.input_width, self.input_height, self.input_channel])\n",
    "        self.Z = tf.placeholder(dtype=tf.float32, shape=[None, self.noise_size])\n",
    "                \n",
    "\n",
    "    def generator(self, noise):\n",
    "        with tf.variable_scope(\"generator_\", reuse = tf.AUTO_REUSE):#tensorboard 추가\n",
    "            noise = tf.convert_to_tensor(noise)\n",
    "            noise = tf.layers.dense(inputs=noise, units = 7*7*1024, bias_initializer = tf.random_normal_initializer())\n",
    "            noise = tf.reshape(noise, [-1, 7, 7, 1024])#7,7,1024\n",
    "            noise = tf.layers.batch_normalization(inputs = noise)\n",
    "            \n",
    "            L1 = tf.layers.conv2d_transpose(noise, 256, [4, 4], strides=(2, 2), padding=\"SAME\")#14,14,256\n",
    "            #print(np.shape(L1))\n",
    "            L1 = tf.layers.batch_normalization(inputs = L1)\n",
    "            Y1 = tf.nn.relu(L1)\n",
    "\n",
    "            L2 = tf.layers.conv2d_transpose(Y1, self.input_channel, [4, 4], strides=(2, 2), padding=\"SAME\")#28,28,1\n",
    "            #print(np.shape(L2))\n",
    "            L2 = tf.layers.batch_normalization(inputs = L2)\n",
    "\n",
    "            self.model_G= tf.nn.tanh(L2)\n",
    "            \n",
    "            return self.model_G\n",
    "    \n",
    "    def discriminator(self, input_data):\n",
    "        with tf.variable_scope(\"discriminator_\", reuse = tf.AUTO_REUSE):\n",
    "            L1 = tf.layers.conv2d(input_data, 128, [5, 5], strides=(2, 2), padding=\"SAME\")#28,28,1 -> 14,14,128\n",
    "            #print(np.shape(L1))\n",
    "            L1 = tf.layers.batch_normalization(inputs = L1)\n",
    "            Y1 = tf.nn.leaky_relu(L1)\n",
    "\n",
    "            L2 = tf.layers.conv2d(Y1, 256, [5, 5], strides=(2, 2), padding=\"SAME\")#14,14,128 -> 7,7,256\n",
    "            #print(np.shape(L2))\n",
    "            L2 = tf.layers.batch_normalization(inputs = L2)\n",
    "            Y2 = tf.nn.leaky_relu(L2)\n",
    "\n",
    "            L3 = tf.layers.conv2d(Y2, 512, [5, 5], strides=(2, 2), padding=\"SAME\")#7,7,256 -> 4,4,512\n",
    "            #print(np.shape(L3))\n",
    "            L3 = tf.layers.batch_normalization(inputs = L3)\n",
    "            Y3 = tf.nn.leaky_relu(L3)\n",
    "\n",
    "            L4 = tf.layers.conv2d(Y3, 1, [5, 5], strides=(2, 2), padding=\"SAME\")#3,3,512 -> 2,2,1\n",
    "            #print(np.shape(L4))\n",
    "            L4 = tf.layers.batch_normalization(inputs = L4)\n",
    "            Y4 = tf.nn.leaky_relu(L4)\n",
    "            \n",
    "            L5 = tf.layers.conv2d(Y4, 1, [5, 5], strides=(2, 2), padding=\"SAME\")#2,2,1 -> 1,1,1\n",
    "            #print(np.shape(L5))\n",
    "            L5 = tf.layers.batch_normalization(inputs = L5)\n",
    "\n",
    "            self.model_D = tf.nn.sigmoid(L5)\n",
    "            #self.d_variables = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope = 'd')\n",
    "\n",
    "            return self.model_D\n",
    "\n",
    "    def model(self):\n",
    "        with tf.name_scope(\"models\") as scope:\n",
    "            self.G = self.generator(self.Z)\n",
    "            self.D_fake = self.discriminator(self.G)\n",
    "            self.D_real = self.discriminator(self.X)\n",
    "            \n",
    "            self.cost_D = tf.reduce_mean(tf.log(self.D_real) + tf.log(1-self.D_fake))#maximize\n",
    "            self.cost_G = tf.reduce_mean(tf.log(1-self.D_fake))#minimize\n",
    "            \n",
    "            self.t_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)\n",
    "            \n",
    "            self.d_vars = [var for var in self.t_vars if var.name.startswith(\"dis\")]\n",
    "            self.g_vars = [var for var in self.t_vars if var.name.startswith(\"gen\")]\n",
    "            \n",
    "            self.Optimize_D = tf.train.AdamOptimizer(learning_rate=0.00002).minimize(-self.cost_D, \\\n",
    "                                                var_list = self.d_vars)\n",
    "            self.Optimize_G = tf.train.AdamOptimizer(learning_rate=0.00002).minimize(self.cost_G, \\\n",
    "                                                var_list = self.g_vars)\n",
    "            \n",
    "            D_cost = tf.summary.scalar(\"d_cost\", self.cost_D)#tensorboard 추가\n",
    "            G_cost = tf.summary.scalar(\"g_cost\", self.cost_G)#tensorboard 추가\n",
    "            \n",
    "            #D_opt = tf.summary.scalar(\"d_opt\", self.Optimize_D)#tensorboard 추가\n",
    "            #G_opt = tf.summary.scalar(\"g_opt\", self.Optimize_G)#tensorboard 추가\n",
    "\n",
    "    def training(self, is_training):\n",
    "        merged_summary = tf.summary.merge_all()#tensorboard 추가\n",
    "        writer = tf.summary.FileWriter(\"C:/Users/JAEKYU/Documents/log_simple_states\")#tensorboard 추가\n",
    "        writer.add_graph(self.sess.graph)#tensorboard 추가\n",
    "        data_size = 55000\n",
    "        total_batch = int(data_size / self.batch_size)\n",
    "        SAVE_PATH = \"C:/Users\\JAEKYU/Documents/Jupyter Notebook/Deep Convolution Generative Adverserial Network/Weight/Weight.ckpt\"   \n",
    "        print(\"Session start\")\n",
    "        \n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        saver = tf.train.Saver()\n",
    "        \n",
    "        if(not is_training):\n",
    "            saver.restore(self.sess, SAVE_PATH)\n",
    "            print(\"weight 값 load 끝~\")\n",
    "            noise_data = make_noise_vector(1, 100)\n",
    "            predict = self.sess.run(self.G, feed_dict={self.Z : noise_data})#1, 28, 28, 1\n",
    "            predict_0 = predict[0]#28, 28, 1\n",
    "            predict_0 = predict_0.reshape(28, 28)\n",
    "            print(np.shape(predict_0))\n",
    "            #predict = predict[0].reshape(28, 28)\n",
    "            plt.imshow(predict_0)\n",
    "            plt.show()\n",
    "            #print(np.shape(predict))\n",
    "\n",
    "            decision = self.sess.run(self.D_fake, feed_dict={self.G : predict})\n",
    "            print(decision)\n",
    "            \n",
    "            input_ = mnist.train.next_batch(batch_size=self.batch_size)[0]#32,784\n",
    "            input_ = input_[0].reshape(-1, self.input_width, self.input_height, self.input_channel)\n",
    "            decision2 = self.sess.run(self.D_real, feed_dict={self.X : input_})\n",
    "            print(decision2)\n",
    "            \n",
    "        else:\n",
    "            for epoch in range(70):\n",
    "                #saver.restore(self.sess, SAVE_PATH)\n",
    "                for i in range(total_batch):\n",
    "                    #batch 만들기\n",
    "                    batch_X = mnist.train.next_batch(batch_size=self.batch_size)[0]#32,784\n",
    "                    batch_X = batch_X.reshape(-1, self.input_width, self.input_height, self.input_channel)\n",
    "                    batch_Z = make_noise_vector(self.batch_size, self.noise_size)#-1,100\n",
    "                    \n",
    "                    Opt_G, cost_G = self.sess.run([self.Optimize_G, self.cost_G], feed_dict={self.Z : batch_Z})\n",
    "                    Opt_D, cost_D, summary = self.sess.run([self.Optimize_D, self.cost_D, merged_summary], feed_dict={self.X : batch_X, self.Z : batch_Z})#tensorboard 추가\n",
    "                    writer.add_summary(summary, global_step = epoch*total_batch + i)#tensorboard 추가\n",
    "                print(\"epoch : \", epoch, \", gen_cost : \", cost_G, \", dis_cost : \", cost_D)\n",
    "                saver.save(self.sess, SAVE_PATH)\n",
    "                \n",
    "                \n",
    "                \n",
    "                noise_data = make_noise_vector(self.batch_size, self.noise_size)#-1 x 100\n",
    "                samples = 255*self.sess.run(self.G, feed_dict={self.Z : noise_data})\n",
    "                samples = np.clip(samples, 0, 255).astype(np.uint8)\n",
    "                buffer = samples[0].reshape(28,28)\n",
    "                misc.imsave(\"./save/%d.jpg\" %epoch, buffer)\n",
    "                #print(buffer)\n",
    "                fig, ax = plt.subplots(1, 1, figsize=(1, 1))\n",
    "                ax.set_axis_off()\n",
    "                ax.imshow(buffer)\n",
    "                fig.show()\n",
    "                plt.draw()\n",
    "                plt.show()\n",
    "                \n",
    "    def testing(self):\n",
    "        noise_data = make_noise_vector(self.batch_size, self.noise_size)#-1 x 100\n",
    "        samples = self.sess.run(self.G, feed_dict={self.Z : noise_data})\n",
    "        buffer = samples[0].reshape(28,28)\n",
    "        print(np.shape(buffer))\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(1, 1))\n",
    "        #for j in range(self.batch_size):\n",
    "        ax.set_axis_off()\n",
    "        ax.imshow(buffer)\n",
    "        #fig.show()\n",
    "        #plt.draw()\n",
    "        #plt.show()\n",
    "    \n",
    "print(\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session start\n",
      "INFO:tensorflow:Restoring parameters from C:/Users\\JAEKYU/Documents/Jupyter Notebook/Deep Convolution Generative Adverserial Network/Weight/Weight.ckpt\n",
      "weight 값 load 끝~\n",
      "(28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x28ffc3b75c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0.00046023]]]]\n",
      "[[[[1.]]]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    dcgan_object = DCGAN(sess=sess, batch_size=64)\n",
    "    dcgan_object.training(False)#False load Weight/ True made Weight\n",
    "    #dcgan_object.testing()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Load--------------------------------------------------------------------------------------\n",
    "img_data = [None]\n",
    "\n",
    "\n",
    "img_data = misc.imread(\"./save/6.jpg\")\n",
    "print(img_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
